<!doctype html>
<html lang="ja">
  <head>
    <meta charset="utf-8">
    <title>プログラマの為の数学勉強会</title>

    <!-- For reveal.js -->
    <link rel="stylesheet" href="lib/reveal/css/reveal.css">
    <link rel="stylesheet" href="lib/reveal/css/theme/night.css">
    <link rel="stylesheet" href="lib/reveal/lib/css/ir_black.css">

    <!-- For Graphics -->
    <link rel="stylesheet" href="css/graphics.css">

    <style>
      .reveal .chapter-title {
        margin-top: 3em;
      }

      .reveal {
        font-size: 32px;
        line-height: 1.4em;
      }

      .reveal .slides {
        text-align: left;
      }

      .reveal section img {
        border: none;
        background: 0;
        margin-left: 1em;
        margin-right: 1em;
        box-shadow: none;
      }

      .reveal strong {
        color: yellow;
      }

      .reveal sup {
        font-size: 40%;
      }

      .reveal table {
        margin-top: 0.5em;
        margin-bottom: 0.5em;
        border: 2px solid lightblue;
      }

      .reveal pre {
        font-size: 0.7em;
      }

      .reveal pre code {
        max-height: 600px;
      }

      .reveal .note {
        font-size: 50%;
      }

      .reveal .controls div.navigate-up,
      .reveal .controls div.navigate-down {
        display: none;
      }

      .reveal .block {
        border: solid 2px;
        position: relative;
        border-radius: 8px;
        margin-top: 0.8em;
        margin-bottom: 0.8em;
        padding: 1em 0.8em 1em 0.8em;
      }

      .reveal .block:after {
        content: "";
        display: block;
        clear: both;
        height: 1px;
        overflow: hidden;
      }

      .reveal .answer {
        color: #111111;
      }

      .reveal .block h4 {
        position: absolute;
        top: -0.5em;
        margin: 0 auto;
        background: #111111;
        font-weight: bold;
      }

    </style>

    <!-- Setup libraries for RequireJS-->
    <script src="lib/require.js"></script>

    <script>
      requirejs.config({
        baseUrl: "js",
        paths: {
          d3: "../lib/d3/d3.v3.min",
          numeric: "../lib/numeric-1.2.6",
          MathJax: "http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"
        },
        shim: {
          d3: { exports: "d3" },
          numeric: { exports: "numeric" },
          MathJax: { exports: "MathJax" }
        }
      });
    </script>

    <!-- Initialize MathJax -->
    <script type="text/x-mathjax-config">
      require(["MathJax"], function (MathJax){
        MathJax.Hub.Register.StartupHook("AsciiMath Jax Config", function () {
          var AM = MathJax.InputJax.AsciiMath.AM;
          AM.symbols.push(
            {input:"mathbi",tag:"mstyle",atname:"mathvariant",atval:"bold-italic",
             output:"mathbi",tex:null,ttype:AM.TOKEN.UNARY}
          );
        });

        MathJax.Hub.Config({
          showProcessingMessages: false,
          skipStartupTypeset: false,
          tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ["\\[","\\]"] ]
          }
        });
      });
    </script>
    <script>
    </script>

  </head>
  <body>
    <div class="reveal">
      <div class="slides">

        <section style="text-align: center">
        <h1> プログラマの為の<br>数学勉強会<br>第12回</h1>
        <span>
          (於)ワークスアプリケーションズ<br>
          中村晃一<br>
          2013年11月28日
        </span>
        </section>

        <section>
        <h2>謝辞</h2>
        <p>
        この会の企画・会場設備の提供をして頂きました<br>
        &#12849; ワークスアプリケーションズ様<br>
        にこの場をお借りして御礼申し上げます。
        </p>
        </section>

        <section>
        <h2> この資料について </h2>
        <p>
        <ul>
          <li> <a href="http://nineties.github.com/math-seminar">
            http://nineties.github.com/math-seminar
            </a>に置いてあります。 </li>
            <li> SVGに対応したブラウザで見て下さい。主要なブラウザで古いバージョンでなければ大丈夫だと思います。</li>
            <li> 内容の誤り、プログラムのバグは<a href="http://twitter.com/9_ties">@9_ties</a>かkoichi.nakamur AT gmail.comまでご連絡下さい。</li>
            <li> サンプルプログラムはPython及びMaximaで記述しています。 </li>
        </ul>
        </p>
        </section>

        <section>
        <h2 class="chapter-title"> 確率論入門  </h2>
        </section>

        <section>
        <p>
        今回から<strong>確率・統計</strong>分野に入ります。
        </p>
        <p>
        最初に<strong>確率</strong>の基礎知識を確認しましょう。
        </p>
        </section>

        <section>
        <p>
        単に「確率」と言ってもいくつかの解釈があります。具体的な問題で考えてみましょう。
        </p>
        <div class="block" style="border-color:pink;font-size:90%">
          <p>
          サイコロを振って\(1\)の目が出る確率が\(\frac{1}{6}\)であるというのはどういう事か？
          <div align="center"> <img width="200" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Sixsided_Dice_inJapan.jpg/320px-Sixsided_Dice_inJapan.jpg"> </div>
          </p>
        </div>
        </section>

        <section>
        <h2> 解釈1 </h2>
        <ul>
          <li class="fragment"> サイコロの目の出方は6通りであり,それらは同様に確からしい。 </li>
          <li class="fragment"> 1の目が出るのはそのうちの1通りの場合である。 </li>
          <li class="fragment"> 従って1の目が出る確率は
          \[ \frac{1}{6} \]
          である。 </li>
        </ul>
        <div class="block fragment" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 組合せ論的確率 </h4>
        <p>
        全ての起こりうる根元事象が\(n\)通りで同様に確かであるとする。
        事象\(A\)を構成する根元事象が\(a\)通りならば,事象\(A\)の起こる確率は
        \[ P(A) = \frac{a}{n} \]
        である。
        </p>
        </div>
        </section>

        <section>
        <p>
        組合せ論的確率では<strong>「同様に確からしい」</strong>という条件が重要です。
        </p>
        <p class="fragment" data-fragment-index="1">
        例えば,以下の様な計算はこの意味で妥当ではないと考えられます。
        </p>
        <div style="float:left" class="fragment" data-fragment-index="1">
          <blockquote style="font-size:90%">
        サイコロを振ったら「1が出る」か「1が出ない」の2通りの場合があるから,1の目がでる確率は\( \frac{1}{2} \)である
          </blockquote>
        </div>
        </section>

        <section>
        <p>
        ところが,そもそも何をもって「同様に確からしい」ということを判断出来るのでしょうか？
        </p>
        <p class="fragment">
        これは純粋に数学的に取り扱える様な問題ではなさそうです。
        例えばサイコロの例では,サイコロの形状や投げ方と言った物理的な状況を考えなければいけません。
        </p>
        </section>

        <section>
        <h2> 解釈2 </h2>
        <ul>
          <li class="fragment">
          1の目が出る確率が\(\frac{1}{6}\)であるというのは,
          サイコロを\(n\)回振ったら,\(\frac{n}{6}\)回程度1の目が出るという事である。
          </li>
          <li class="fragment">
          振る回数を増やすほど以下の値は\(\frac16\)に近づいていくのである。
          \[ \frac{\text{1の目が出た回数}}{\text{振った回数}} \]
          </li>
        </ul>
        <div class="block fragment" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 統計的確率 </h4>
        <p>
        \(n\)回試行を行った時に,事象\(A\)が\(a\)回起こったとする。
        \(A\)の起こる頻度
        \[ \frac{a}{n} \]
        が\(n\rightarrow\infty\)の時,ある定数に(ほとんど確実に)近づいていくならば,その値が\(A\)の起こる確率\(P(A)\)である。
        </p>
        </div>
        </section>

        <section>
        <p>
        「組合せ論的確率も統計的確率も結局同じ値になるんじゃないの？」と思った人もいると思います。統計的確率を実際に計算するのは困難なので,もしそうならありがたいです。これは後に<strong>大数の法則</strong>として説明されます。
        </p>
        <p class="fragment">
        また,これらの値は客観的に定まるので<strong>客観的確率</strong>とも呼ばれます。<br>
        </p>
        <p class="fragment">
        こういった個数・頻度を数える事に基づく確率の考え方を<strong>頻度主義</strong>とも言います。
        </p>
        </section>

        <section>
        <h2> 解釈3 </h3>
        <ul>
          <li class="fragment"> サイコロの1～6のいずれの目が出やすいのかはわからない。 </li>
          <li class="fragment"> よって\(i\)の目が出るということの確信度\(P(i)\)を数値にするならば
          \[ P(1) = P(2) = P(3) = P(4) = P(5) = P(6) \]
          である。 </li>
          <li class="fragment"> よって確信度の総和を\(1\)とするならば
          \[ P(1) = \frac{1}{6} \]
          である。 </li>
        </ul>
        <div class="block fragment" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 主観的確率 </h4>
        <p>
        事象\(A\)の起こる確率\(P(A)\)とは,事象\(A\)が起こるということの確信度(信念の度合い)を\(0\leq P(A)\leq 1\)で数量化したものである。
        </p>
        </div>
        </section>

        <section>
        <p>
        確率の主観的な解釈は数学者トーマス・ベイズの名をとって<strong>ベイズ主義</strong>とも呼ばれます。
        </p>
        <p class="fragment" data-fragment-index="1">
        ベイズ主義では
        </p>
        <ul class="fragment" data-fragment-index="1">
          <li> <strong>確率を考える主体によってその値が変わり得る</strong> </li>
          <li> <strong>新たな情報を得る事でその値が変わり得る</strong> </li>
        </ul>
        <p class="fragment" data-fragment-index="1">
        という点に注意しましょう。
        </p>
        <p class="fragment">
        先ほどの\(\frac16\)という値は「出目の偏りについて何も情報がない」事から暫定的に求められた値です。実際にサイコロを振ってみて新たな情報を得ると,その値も変化していくでしょう。
        </p>
        </section>

        <section>
        <p>
        サイコロの例だと主観確率という考え方が必要になる理由が分かりにくいと思いますので例を変えましょう。
        </p>
        <p class="fragment" data-fragment-index="1">
        あるシステム上でユーザー毎に最適な広告を表示する仕組みを作りたいとしましょう。この場合,
        <strong>\(A\)さんが商品\(X\)を購入してくれる確率\(P\)</strong>といったものを考える必要が生じます。
        </p>
        <div class="fragment" data-fragment-index="1" align="center"> <img width="300" src="fig/advertisement-suggestion.png"> </div>
        <p class="fragment">
        この\(P\)を頻度主義的な考え方で数量化するのは難しいでしょう。
        </p>
        <p class="fragment">
        また\(A\)さんの新しい行動がある度に\(P\)の値も更新されるべきでしょう。
        </p>
        </section>

        <section>
        <h2> 本勉強会で学ぶ統計学 </h2>
        <p>
        以上,代表的な確率の解釈を紹介しました。
        </p>
        <ul>
          <li> 客観確率(頻度主義)
            <ul>
              <li> 組合せ論的 </li>
              <li> 統計的 </li>
            </ul>
          </li>
          <li> 主観確率(ベイズ主義) </li>
        </ul>
        <p class="fragment" data-fragment-index="1">
        土台とする確率論が異なれば,統計学の形も異なります。<br>
        この勉強会では
        </p>
        <ol class="fragment" data-fragment-index="1">
          <li> <strong style="font-size:120%">頻度主義に基づく推計統計学</strong> </li>
          <li> <strong style="font-size:120%">ベイズ主義に基づくベイズ統計学</strong> </li>
        </ol>
        <p class="fragment" data-fragment-index="1">
        をこの順番に学んでいきます。
        </p>
        </section>

        <section>
        <h2 class="chapter-title"> 公理的確率論 </h2>
        </section>

        <section>
        <p>
        続いて,確率の数学的な取り扱いについて説明します。
        </p>
        <p class="fragment" data-fragment-index="1">
        これまで説明したいずれの確率解釈も純粋に数学的に取り扱う事の難しい概念を含んでいます。
        </p>
        <ul class="fragment" data-fragment-index="1">
          <li> 組合せ論的解釈:「同様に確からしい」とは? </li>
          <li> 統計的解釈: 「試行」とは? </li>
          <li> ベイズ的解釈: 「確信度」とは? </li>
        </ul>
        <p class="fragment">
        こういった哲学的な話題はこの勉強会では扱いません(私もよくわかりません)。
        </p>
        </section>

        <section>
        <h2> 公理的確率論 </h2>
        <p>
        そこで,「公理」という考え方が必要になります。
        </p>
        <ul>
          <li class="fragment"> 確率などの概念は<strong>未定義語</strong>とする。 </li>
          <li class="fragment"> 「もし\(P(A)\)を\(A\)の確率と呼ぶのならば,\(P\)はどういった性質を満たすべきか？」という事を<strong>公理</strong>として記述する。 </li>
          <li class="fragment"> 公理に基いて確率論の数学体系を構築する。 </li>
        </ul>
        <p class="fragment" data-fragment-index="4">
        具体的な確率の定義はいろいろあっても,確率論の公理さえ満たせばその体系で示された全ての定理が使用出来る事になります。
        </p>
        <div class="fragment" data-fragment-index="4" align="center"> <img width="700" src="fig/axiomatic_probability_theory1.png"> </div>
        </section>

        <section>
        <h2> 事象 </h2>
        <p>
        <strong>事象</strong>は数学的には<strong>集合</strong>として表現します。
        </p>
        <p class="fragment">
        「起こりうる全ての場合(<strong>全事象</strong>)」を表す集合\(\color{yellow}{\Omega}\)\((\neq\phi)\)を固定した上で,
        個々の事象を\(\Omega\)の部分集合であるとして考えます。
        </p>
        <div class="fragment block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        サイコロを1つ振るという試行は,以下のように集合で表す事ができます。
        </p>
        \[
        \begin{aligned}
        \text{全事象} &:\ \Omega = \{1,2,3,4,5,6\} \\
        \text{1の目が出るという事象$A$} &:\ A = \{1\} \\
        \text{偶数の目が出るという事象$B$} &:\ B = \{2,4,6\}
        \end{aligned}
        \]
        </div>
        </section>

        <section>
        <p>
        【注意】<br>
        <p>
        本来「任意の事象(事象とは？)を集合で表す(表すとは?)事が出来る」か否かといった事は数学的に議論出来る事ではありません。<br>
        従って,
        </p>
        <blockquote style="font-size:90%">
          \(\Omega\)を全事象を表す集合とする。
        </blockquote>
        <p>
        みたいな言い方は良くなくて,単に
        </p>
        <blockquote style="font-size:90%">
        \(\Omega\)は集合である。
        </blockquote>
        <p>
        と言うべきです。
        </p>
        <p>
        本資料の解説文では,理解を助ける為に前者の様な書き方を多用しますので注意してください。
        </p>
        </section>

        <section>
        <h2> 余事象 </h2>
        <p>
        「\(A\)が起こらない」という事象を\(A\)の<strong>余事象</strong>と言います。
        </p>
        <p>
        数学的には,集合\(A\)の\(\Omega\)上での<strong>補集合</strong>
        \[ A^c = \{x\in\Omega\ |\ x\not\in A\} \]
        を\(A\)の余事象に対応する集合であると考える事ができます。
        </p>
        <div align="center"> <img width="400px" src="fig/set1.png"> </div>
        </section>

        <section>
        <h2> 和事象 </h2>
        <p>
        「\(A,B\)のいずれかが起こる」という事象を\(A,B\)の<strong>和事象</strong>と言います。
        </p>
        <p>
        数学的には,集合\(A,B\)の<strong>和集合</strong>
        \[ A\cup B = \{x\in\Omega | x\in A\ \text{または}\ x\in B\} \]
        を\(A,B\)の和事象に対応する集合であると考える事ができます。
        </p>
        <div align="center"> <img width="400px" src="fig/set2.png"> </div>
        </section>

        <section>
        <h2> 積事象 </h2>
        <p>
        「\(A,B\)が共に起こる」という事象を\(A,B\)の<strong>積事象</strong>と言います。
        </p>
        <p>
        数学的には,集合\(A,B\)の<strong>積集合</strong>
        \[ A\cap B = \{x\in\Omega | x\in A\ \text{かつ}\ x\in B\} \]
        を\(A,B\)の積事象に対応する集合であると考える事ができます。
        </p>
        <div align="center"> <img width="400px" src="fig/set3.png"> </div>
        </section>

        <section>
        <p>
        同様に,加算個の事象\(A_1,A_2,\cdots\)に対してもその和事象・積事象を考える事が可能であるとすれば,
        対応する集合は
        \[ \begin{aligned}
        \bigcup_{i=1}^{\infty}A_i &= A_1\cup A_2\cup \cdots  \\
        \bigcap_{i=1}^{\infty}A_i &= A_1\cap A_2\cap \cdots 
        \end{aligned} \]
        となります。
        </p>
        <p>
        有限個の集合の和集合・積集合も
        \[ \begin{aligned}
        A_1\cup \cdots \cup A_n &= A_1\cup\cdots \cup A_n\cup\color{yellow}{\phi\cup\phi\cdots} \\
        A_1\cap \cdots \cap A_n &= A_1\cap\cdots \cap A_n\cap\color{yellow}{\Omega\cap\Omega\cdots} \\
        \end{aligned} \]
        と表せますので,数学的には加算個の場合だけを考えれば十分です。
        </p>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> ド・モルガンの法則 </h4>
        <p>
        集合\(A,B\)に対して
        \[ (A\cup B)^c = A^c \cap B^c,\qquad (A\cap B)^c = A^c \cup B^c \]
        が成り立つ。加算個の集合に対しては
        \[ \left(\bigcup_{i=1}^{\infty} A_i\right)^c = \bigcap_{i=1}^{\infty}A_i^c,\qquad 
        \left(\bigcap_{i=1}^{\infty} A_i\right)^c = \bigcup_{i=1}^{\infty}A_i^c 
        \]
        が成り立つ。
        </p>
        </div>
        <p style="font-size:80%">
        集合を事象と解釈するならば,\((A\cup B)^c = A^c \cap B^c\)という等式は,
        「「\(A,B\)のいずれかが起こる」という事が起こらない」という事と
        「\(A,B\)は共に起こらない」という事が同じ事象であるという意味になります。他の等式についても考えてみてください。
        </p>
        </section>

        <section>
        <p>
        ド・モルガンの法則より
        \[ A_1\cap A_2\cap \cdots = (A_1^c\cup A_2^c\cup \cdots)^c \]
        という形で<strong>積集合は補集合・和集合で表せる</strong>事がわかります。
        </p>
        <p class="fragment">
        積集合の記法は今後も使いますが,原理的には補集合・和集合のみで全ての数学的な議論を進める事ができるという事になります。
        これは特に証明を行う場合に便利です。
        </p>
        </section>

        <section>
        <h2> 排反 </h2>
        <p>
        「\(A,B\)が共に起こることはない」とき,事象\(A,B\)は<strong>排反</strong>であると言います。
        </p>
        <p>
        数学的には集合\(A,B\)が互いに素であること,つまり
        \[ A\cap B = \phi \]
        である事として表現する事が出来ると考えられます。
        </p>
        <div align="center"> <img width="400px" src="fig/set5.png"> </div>
        </section>

        <section>
        <p>
        さて,集合\(\Omega\)の部分集合のうち「事象」として考えたいものだけを集めた集合を\(\color{yellow}{\mathcal{F}}\)としましょう。
        </p>
        <div class="fragment block" style="border-color:lightgreen;font-size:80%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        サイコロを1つ振るという試行の場合、\(\Omega=\{1,2,3,4,5,6\}\)として
        \[ \begin{aligned}
        \mathcal{F} &= 2^{\Omega} \\
        &= \{\phi,\{1\},\{2\},\cdots,\{6\},\{1,2\},\{1,3\},\cdots,\{1,2,3,4,5,6\}\}
        \end{aligned} \]
        つまり\(\mathcal{F}=(\Omega\text{のべき集合})\)と置けば良いです。
        </p>
        </div>
        </section>

        <section>
        <p>
        今の例では,\(\Omega\)に対して
        \[ \mathcal{F} = 2^{\Omega}\quad\text{($\Omega$の部分集合全てからなる集合)} \]
        とおきましたが,こうでなければならない理由はありません。特に\(\Omega\)が無限集合の場合には\(\mathcal{F}=2^{\Omega}\)だと困る場合があります。
        </p>
        <div class="fragment block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        \(\mathcal{F}=2^{\Omega}\)でない有限集合での例を無理やり作ってみましょう。
        </p>
        <p> 「サイコロを振るけど,偶数か奇数かしか注目しない」というのならば
        \[ \mathcal{F} = \{\phi, \{1,3,5\},\{2,4,6\},\{1,2,3,4,5,6\}\} \]
        という集合を「事象の集合」として考える事ができます。
        </p>
        </div>
        <p class="fragment">
        ということで\(\mathcal{F}\)はある程度自由に取れるわけですが,全く自由というわけではありません。
        </p>
        </section>

        <section>
        <h2> 完全加法族 </h2>
        <p> 集合\(\mathcal{F}\)は以下の条件を満たすようなものだけを考える事とします。 </p>
        <div class="block" style="border-color:pink;font-size:90%">
        <p>
        集合\(\Omega\)のべき集合の部分集合\(\mathcal{F}\subset 2^{\Omega}\)が以下の条件を満たす時,
        \(\mathcal{F}\)を\(\Omega\)上の<strong>完全加法族</strong>と言う。
        </p>
        \[ \begin{aligned}
        1. &\mathcal{F} \neq \phi \\
        2. &A\in\mathcal{F}\ \text{ならば}\ A^c\in\mathcal{F} \\
        3. &A_1,A_2,\cdots\in\mathcal{F}\ \text{ならば}\ \bigcup_{i=1}^{\infty}A_i \in \mathcal{F}
        \end{aligned} \]
        <p>
        </div>
        </section>

        <section>
        <p>
        \(\mathcal{F}\)を「事象の集合」と解釈すれば,条件1,2,3は以下のように解釈できます。
        </p>
        <div class="block" style="border-color:pink;font-size:90%">
        \[ \begin{aligned}
        1. & \text{少なくとも1つ事象が存在する} \\
        2. & \text{事象$A$に対して,その余事象を考える事が出来る} \\
        3. & \text{事象$A_1,A_2,\cdots$に対して,それらの和事象を考える事が出来る}
        \end{aligned} \]
        </div>
        <p>
        数学的な定義は難しく感じるかもしれませんが,上のようなイメージを持つことが出来れば当たり前に感じられるでしょう。
        </p>
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 練習問題 </h4>
        <p> \(\mathcal{F}\)が\(\Omega\)上の完全加法族の時 </p>
        \[ \begin{aligned}
        &A_1,A_2,\cdots\in\mathcal{F}\ \text{ならば}\ \bigcap_{i=1}^{\infty}A_i \in\mathcal{F} \\
        &\Omega,\phi \in \mathcal{F}
        \end{aligned} \]
        <p>
        である事を証明してください。また,\(\mathcal{F}\)を事象の集合と解釈するならば,それぞれどのような意味でしょうか？
        </p>
        </div>
        <p class="fragment" style="font-size:80%">
        【証明】<br>
        1つ目はド・モルガンの法則より。<br>
        2つ目について。\(\mathcal{F}\neq\phi\)であることよりある\(A\in\mathcal{F}\)が存在する。よって
        \[ \Omega = A\cup A^c \in \mathcal{F},\quad \phi = A\cap A^c \in \mathcal{F} \]
        <span style="float:right">□</span>
        </p>
        </section>

        <section>
        <p>
        よく使われる完全加法族はべき集合\(2^{\Omega}\)と,<strong>ボレル集合族</strong>です。
        </p>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> ボレル集合族 </h4>
        <p>
        \(\Omega=\mathbb{R}\)の場合,\((a,b)\)や\((a,\infty)\)や\((-\infty,a)\)など任意の開集合(端を含まない区間)を含む最小の完全加法族を<strong>ボレル集合族</strong>といい
        \[ \mathcal{B}(\mathbb{R})\]
        などと書く。<br>
        \(n\)次ユークリッド空間\(\mathbb{R}^n\)に対しても同様に,その任意の開集合(境界を含まない集合)を含む最小の完全加法族\(\mathcal{B}(\mathbb{R}^n)\)が定義される。
        </p>
        </div>
        <p>
        難しく感じますが,数直線\(\mathbb{R}\)上の区間,平面\(\mathbb{R}^2\)内の図形,空間\(\mathbb{R}^3\)内の立体などで通常イメージするものを全て含んでいる集合だと思ってください。
        </p>
        </section>

        <section style="font-size:90%">
        <h2> 確率空間 </h2>
        <div class="block" style="border-color:pink;font-size:90%">
        <p>
        \(\Omega\)を集合,\(\mathcal{F}\)を\(\Omega\)上の完全加法族とする。
        \(\mathcal{F}\)上の実数値関数\(P: \mathcal{F}\rightarrow\mathbb{R}\)が,
        \[ \begin{aligned}
        1. & P(A)\geq 0\\
        2. & A_1,A_2,\cdots\text{が互いに素の時}\\ 
        & P\left(\bigcup_{i=1}^{\infty}A_i\right) = \sum_{i=1}^{\infty}P(A_i) \qquad\color{yellow}{\text{(完全加法性)}}\\
        3. & P(\Omega) = 1\\
        \end{aligned} \]
        を満たす時,\((\Omega, \mathcal{F}, P)\)の事を<strong>確率空間</strong>と言う。<br>
        \(\Omega\)を標本空間,\(\Omega\)の元を標本,\(\mathcal{F}\)の元を事象,特に\(\Omega\in\mathcal{F}\)を全事象と呼ぶ。\(\mathcal{F}\)の元が互いに素である時,それらは排反であるという。\(P\)を確率測度,\(P(A)\)を事象\(A\)の確率と呼ぶ。
        </p>
        </div>
        </section>

        <section>
        <p>
        再び,わかりやすく翻訳すれば
        </p>
        <div class="block" style="border-color:pink;font-size:90%">
        \[ \begin{aligned}
        1. & \text{任意の事象の確率は$0$以上である} \\
        2. & \text{事象$A_1,A_2,\cdots$が排反ならば,}\\
           & \text{いずれかが起こる確率は各事象の確率の和である}\\
        3. & \text{全事象の確率は$1$である} \\
        \end{aligned} \]
        </div>
        <p>
        となります。
        </p>
        </section>

        <section>
        <p>
        確率測度\(P\)はよく使うので,今後以下のような記号の濫用を行います。
        </p>
        \[ \begin{aligned}
        P(a) &= P(\{a\})\qquad (a\in\Omega) \\
        P(\text{条件}) &= P(\{x\in\Omega\ |\ x\text{は(条件)を満たす}\})
        \end{aligned} \]
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 練習問題 </h4>
        <p>
        確率測度\(P\)に対して
        \[ P(\phi) = 0 \]
        である事を示してください。
        </p>
        </div>
        <p class="fragment" style="font-size:80%">
        【証明】<br>
        \(\Omega = \Omega\cup\phi\cup\phi\cdots\)であり,\(\Omega,\phi\)は互いに素であるから,完全加法性より
        \[ P(\Omega) = P(\Omega) + P(\phi) + P(\phi) + \cdots \]
        である。よって
        \[ 1 = 1 + P(\phi) + P(\phi) + \cdots \]
        であるから
        \[ P(\phi) = 0 \]
        である。
        <span style="float:right">□</span>
        </p>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 有限加法性 </h4>
        <p>
        \(P\)を確率測度とする。互いに素な事象\(A_1,\cdots,A_n\)に対して
        \[ P\left(\bigcup_{i=1}^{n}A_i\right) = \sum_{i=1}^nP(A_i) \]
        が成立する。
        </p>
        </div>
        <p style="font-size:80%">
        【証明】<br>
        \(A_1\cup\cdots \cup A_n = A_1\cup\cdots\cup A_n\cup\phi\cup\phi\cup\cdots\)であるので,完全加法性より
        \[ \begin{aligned}
        P(A_1\cup\cdots \cup A_n) &= P(A_1)+\cdots +P(A_n) + P(\phi) + P(\phi) + \cdots \\
                                  &= P(A_1)+\cdots +P(A_n)\quad(\because P(\phi)=0)
        \end{aligned} \]
        <span style="float:right">□</span>
        </p>
        </section>

        <section style="font-size:90%">
        <p>
        集合\(X\)と,\(X\)上の完全加法族\(\mathcal{F}\)に対して,\(\mathcal{F}\)上の関数\(\mu:\mathcal{F}\rightarrow [0,\infty]\)が
        \[ \mu(\phi) = 0 \text{かつ完全加法的である} \]
        ならば,\(\mu\)を<strong>測度</strong>と呼びます。
        </p>
        <p class="fragment" data-fragment-index="1">
        <strong> 測度は集合の大きさの抽象化</strong>と言え,集合の元の数・図形の面積・確率などの概念を包括しています。<span style="font-size:70%">(ただし,有限加法性でなく完全加法性を考えるので直感の及ばないところまで一般化されます。)</span>
        </p>
        <div align="center" class="fragment" data-fragment-index="1"> <img width="600px" src="fig/measure.png"> </div>
        <p class="fragment">
        この勉強会では前提としませんが,<strong>測度論</strong>の基礎的な知識があると確率・統計の理解も深まります。
        </p>
        </section>

        <section style="font-size:90%">
        <div class="block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 練習問題 </h4>
        確率測度\(P\)について以下が成り立つ事を証明してください。
        \[ \begin{aligned}
        & P(A^c) = 1-P(A) \\
        & A\subset B\ \text{ならば}\ P(A)\leq P(B) \\
        & A\subset B\ \text{ならば}\ P(B\setminus A)=P(B)-P(A)\quad(B\setminus A = B\cap A^c)
        \end{aligned} \]
        </div>
        <p class="fragment" style="font-size:80%">
        【証明】<br>
        \(\Omega=A\cup A^c\)で\(A,A^c\)は互いに素だから
        \[ P(\Omega)=P(A)+P(A^c)\ \Leftrightarrow\ P(A^c)=1-P(A) \]
        \(A\subset B\)の時\(B=(B\cap A^c)\cup A\)であり,\(B\cap A^c, A\)は互いに素だから
        \[ P(B)=P(B\cap A^c)+P(A)\ \Leftrightarrow\ P(B\setminus A)=P(B)-P(A) \]
        また\(P(B\setminus A)\geq 0\)であるから\(P(A)\leq P(B)\)
        <span style="float:right">□</span>
        </p>
        </section>

        <section style="font-size:90%">
        <div class="block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 練習問題:確率の加法定理 </h4>
        <p>
        確率測度\(P\)について以下が成り立つことを証明してください。
        \[ \begin{aligned}
        P(A\cup B) &= P(A)+P(B) - P(A\cap B) \\
        P(A\cup B) &= P(A)+P(B)\qquad\text{($A,B$が排反のとき)}
        \end{aligned} \]
        </p>
        </div>
        <p class="fragment" style="font-size:80%">
        【証明】<br>
        \(A\cup B=A\cup (B\cap A^c)\)であり,\(A, B\cap A^c\)は互いに素だから
        \[ P(A\cup B) = P(A) + P(B\cap A^c) \]
        また\(B\cap A^c = B\setminus (A\cap B)\)であり\(A\cap B\subset B\)であるから
        \[ P(B\cap A^c) = P(B)-P(A\cap B) \]
        である。従って
        \[ P(A\cup B) = P(A) + P(B)-P(A\cap B) \]
        である。また\(A,B\)が排反の時は\(A\cap B=\phi\)であるから
        \[ P(A\cup B)=P(A)+P(B)-P(\phi)=P(A)+P(B) \]
        である。
        <span style="float:right">□</span>
        </p>
        </section>

        <section>
        <h2> 確率測度の例 </h2>
        <p>
        標本空間を有限集合\(\Omega\),\(\mathcal{F}=2^{\Omega}\)として,
        \[ P(A) = \frac{\#(A)}{\#(\Omega)} \quad\text{($\#(A)$は$A$の元の数)}\]
        とすれば,これは確率測度となります。
        </p>
        <div class="fragment block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        \(\Omega=\{1,2,3,4,5,6\}\)に対して上の確率測度を考えれば,サイコロの数学的なモデルとなります。
        </p>
        </div>
        </section>

        <section>
        <h2> 確率測度の例 </h2>
        <p>
        より一般的な設定として,標本空間を有限集合\(\Omega = \{x_1,\cdots,x_n\}\),\(\mathcal{F}=2^{\Omega}\)として,
        \[ P(x_1) + \cdots + P(x_n)=1 \]
        となる様に各\(P(x_i)\geq 0\)の値を定めれば確率測度\(P\)が定まります。
        </p>
        <div class="fragment block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        例えば,いびつなコインを
        \[ \begin{aligned}
        &\Omega=\{\text{表},\text{裏}\},\quad\mathcal{F}=2^{\Omega}\\
        &P(\text{表})=\frac{51}{100},\ P(\text{裏})=\frac{49}{100}
        \end{aligned} \]
        のような確率測度でモデル化する事ができます。
        </p>
        </div>
        </section>

        <section>
        <h2> 確率測度の例 </h2>
        <p>
        \(\Omega=\mathbb{R},\ \mathcal{F}=\mathcal{B}(\mathbb{R})\)として,
        定数\(a,b\ (a < b)\)を定めて,区間\((a,b)\)に含まれる区間\((x,y)\)に対して
        \[ P((x,y)) = \frac{y-x}{b-a} \]
        区間\((a,b)\)と交わらない集合\(A\)について\(P(A)=0\)と定義すれば確率測度\(P\)が定まります。
        </p>
        <div class="fragment block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        区間\((0,1)\)からランダムに実数\(x\)を選んだ場合,\(0.3 < x < 0.5\)である確率は
        \[ P((0.3,0.5)) = \frac{0.5-0.3}{1-0} = 0.2 \]
        と計算されます。
        </p>
        </div>
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 練習問題 </h4>
        <p>
        今の確率測度\(P\)に関して,
        \[ \begin{aligned}
        P(x) &= 0 \qquad (x\in\mathbb{R})\\
        P([x,y]) &= P((x,y)) \\
        \end{aligned} \]
        である事を示してください。
        </p>
        </div>
        <p class="fragment" style="font-size:70%">
        【証明】<br>
        \(\mathbb{R} = (-\infty,x)\cup\{x\}\cup(x,\infty)\)より
        \[ 1 = P((-\infty,x))+P(x) + P((x,\infty)) \]
        である。\(x\in(a,b)\)の時は
        \[ P((-\infty,x))=P(a,x)=\frac{x-a}{b-a},\ P((x,\infty))=P(x,b)=\frac{b-x}{b-a} \]
        なので\(P((-\infty,x))+P((x,\infty))=1\)となるから\(P(x)=0\)。他の場合も同様。<br>
        また, \([a,b]=\{a\}\cup(a,b)\cup\{b\}\)であるから
        \[ P([a,b])=P(a)+P((a,b))+P(b)=P((a,b)) \]
        <span style="float:right">□</span>
        </p>
        </section>

        <section>
        <p>
        今の練習問題から
        \[ \color{yellow}{ P(A) = 0\ \text{は事象$A$が起こらないという事ではない}} \]
        という事がわかります。同様に
        \[ \color{yellow}{ P(A)=1\ \text{は事象$A$が絶対起こるという事ではない}} \]
        という事もわかります。
        </p>
        <p>
        例えば,\((0,1)\)から実数をランダムに選んだ場合\(0.5\)が選ばれる確率は
        \[ P(0.5) = 0 \]
        となりますが,これが\(0.5\)が決して選ばれないという事を意味するとは考えにくいです。
        </p>
        </section>

        <section>
        <h2 class="chapter-title"> 確率変数・確率分布 </h2>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 確率変数 </h4>
        <p>
        \((\Omega,\mathcal{F},P)\)を確率空間とする。<br>
        \(\Omega\)上の実数値関数\(X: \Omega\rightarrow\mathbb{R}\)を<strong>確率変数</strong>という。<br>
        </p>
        <p>
        \(X\)が確率変数ならば,任意の実数値関数\(f: \mathbb{R}\rightarrow\mathbb{R}\)について\(f\circ X\)も確率変数となる。これを\(f(X)\)を書く。
        </p>
        </div>
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        サイコロを振る試行において
        \[ 
        X = \left\{\begin{array}{ll}
        1 & (\text{$1$が出た時}) \\
        0 & (\text{$1$以外が出た時}) \\
        \end{array}\right.
        \]
        と置けばこれは確率変数\(X\)となります。
        </p>
        </div>
        <p style="font-size:80%">
        この時,\(\Omega_X=\{0,1\},\ \mathcal{F}_X=2^{\Omega_X}\)
        \[ P_X(0)=\frac56,\ P_X(1)=\frac16\]
        と置けば新たな確率空間\((\Omega_X,\mathcal{F}_X,P_X)\)を作る事ができることに注意しましょう。確率変数\(X\)を定めると,\(X\)の値を標本とする確率空間を新たに作ることができます。
        </p>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 確率分布 </h4>
        確率空間\((\mathbb{R},\mathcal{B}(\mathbb{R}),P)\)を<strong>確率分布</strong>と言う。<br>
        (より一般に,確率空間\((\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n),P)\)を確率分布と言う。)
        </p>
        </div>
        </section>

        <section>
        <p>
        確率分布では,確率密度関数で表されるものが重要です。
        </p>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 確率密度関数 </h4>
        <p>
        ある非負実数値関数\(\rho:\mathbb{R}\rightarrow\mathbb{R}\)が存在して,区間\((a,b)\)に対する確率測度が
        \[ P((a,b)) = \int_a^b \rho (x)\mathrm{d}x \]
        と表されるならば,\(\rho\)をこの確率分布の<strong>確率密度関数</strong>と言う。
        </p>
        <p>
        (標本空間として\(\mathbb{R}^n\)をとった場合には、重積分で定義されます。)
        </p>
        </div>
        <div align="center"> <img width="500px" src="fig/measure2.png"> </div>
        </section>

        <section style="font-size:90%">
        <h2> 離散的な確率分布 </h2>
        <p>
        確率分布の定義では標本空間が\(\mathbb{R}\)なので,離散的な値を取る確率分布をどうするのか疑問であると思います。
        </p>
        <p class="fragment">
        この場合,例えばサイコロをモデル化するのであれば
        \[ \begin{aligned}
        &P(1)=P(2)=P(3)=P(4)=P(5)=P(6)=\frac16\\
        &P(A) = 0\quad(\text{$1,2,3,4,5,6\not\in A$のとき})
        \end{aligned} \]
        という確率測度を考えれば良いです。
        </p>
        </section>

        <section>
        <p>
        離散的な確率分布の場合も<strong>確率質量関数</strong>と呼ばる概念を考える事が出来ますが,
        </p>
        <div align="center"> <img width="400px" src="fig/measure3.png"> </div>
        <p>
        もっとわかりやすく、離散的な確率分布とは
        \[ \begin{array}{|c|c|c|c|}\hline
        X        & x_1 & x_2 & \cdots \\ \hline
        P(X=x_i) & p_1 & p_2 & \cdots \\ \hline
        \end{array} \]
        という表の事だと考えて下さい。
        </p>
        </section>

        <section>
        <h2> 期待値 </h2>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 離散的な確率分布における期待値 </h4>
        <p>
        離散的な確率分布
        \[ \begin{array}{|c|c|c|c|}\hline
        X        & x_1 & x_2 & \cdots \\ \hline
        P(X=x_i) & p_1 & p_2 & \cdots \\ \hline
        \end{array} \]
        上の確率変数\(f(X)\)の期待値は
        \[ E[f(X)] = \sum_{i=1}^{\infty}f(x_i)p_i \]
        である。<br>
        <span style="font-size:70%"> (無限和で書いていますが,特別な場合として有限和も含みます。あるところから先を\(p_{n+1}=p_{n+2}=\cdots = 0\)とすれば良いです。） </span>
        </p>
        </div>
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:80%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        サイコロの出目\(X\)の確率分布
        \[ \begin{array}{|c|c|c|c|c|c|c|}\hline
        X        & 1 & 2 & 3 & 4 & 5 & 6 \\ \hline
        P(X=x_i) & \frac16&\frac16&\frac16&\frac16&\frac16&\frac16\\ \hline
        \end{array} \]
        において,\(f(X)=X^2\)の期待値を考えてみましょう。
        </p>
        </div>
        <p style="font-size:80%">
        \[\begin{aligned}
        E[X^2] &= 1^2\cdot\frac16 + 2^2\cdot\frac16 + 3^2\cdot\frac16 + 4^2\cdot\frac16 + 5^2\cdot\frac16 + 6^2\cdot\frac16\\
        &= \frac{91}{6}
        \end{aligned} \]
        </p>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 連続的な確率分布における期待値 </h4>
        <p>
        確率分布\((\mathbb{R},\mathcal{B}(\mathbb{R}),P)\)において,確率測度が確率密度関数\(\rho(x)\)を用いて表されるならば,\(f\)の期待値は
        \[ E[f(X)] = \int_{-\infty}^{\infty}f(x)\rho(x)\mathrm{d} x\]
        である。
        </p>
        </div>
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:80%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        確率密度関数が
        \[ \rho(x) = \left\{\begin{array}{ll}
        2x & (0\leq x \leq 1\text{のとき}) \\
        0 & (\text{それ以外のとき})
        \end{array}\right. \]
        である分布において,\(f(X)=X\)の期待値を考えてみましょう。<br>
        </p>
        <div align="center"> <img width="300px" src="fig/measure5.png"> </div>
        </div>
        <p>
        \[ E[X] = \int_{-\infty}^{\infty}x\rho(x)\mathrm{d} x = \int_0^12x^2\mathrm{d}x = \frac{2}{3} \]
        </p>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 平均・分散・標準偏差 </h4>
        <p>
        期待値\(E[X]\)を,その確率分布の<strong>平均</strong>という。
        </p>
        <p>
        平均が\(\mu=E[X]\)である時,期待値\(V[X] = E[(X-\mu)^2]\)を,その分布の<strong>分散</strong>と言い,分散の平方根\( \sigma[X] = \sqrt{V[X]}\)
        を<strong>標準偏差</strong>という。
        </p>
        </div>
        <p>
        分散は,確率分布の平均の周りの広がり具合を数量化したものです。
        </p>
        <div align="center"> <img width="500px" src="fig/variance.png"> </div>
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:80%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        サイコロの出目\(X\)の確率分布
        \[ \begin{array}{|c|c|c|c|c|c|c|}\hline
        X        & 1 & 2 & 3 & 4 & 5 & 6 \\ \hline
        P(X=x_i) & \frac16&\frac16&\frac16&\frac16&\frac16&\frac16\\ \hline
        \end{array} \]
        の平均・分散・標準偏差を調べましょう。
        </p>
        </div>
        <p style="font-size:70%">
        平均は
        \[ E[X] = 1\cdot\frac16 + 2\cdot\frac16 + 3\cdot\frac16 + 4\cdot\frac16 + 5\cdot\frac16 + 6\cdot\frac16 = \frac72\]
        分散は
        \[ V[X] = E[(X-7/2)^2] = (1-7/2)^2\cdot\frac16 + \cdots + (6-7/2)^2\cdot\frac16 = \frac{35}{12} \]
        標準偏差は
        \[ \sigma[X] = \sqrt{\frac{35}{12}} \approx 1.7 \]
        </p>
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:80%">
        <h4 style="color:lightgreen"> 練習問題 </h4>
        <p>
        確率密度関数
        \[ \rho(x) = \left\{\begin{array}{ll}
        1 & \text{($0\leq x \leq 1$のとき)} \\
        0 & \text{(それ以外)}
        \end{array}\right. \]
        で定まる確率分布の平均・分散・標準偏差を求めて下さい。
        </p>
        <div align="center"> <img width="300px" src="fig/measure6.png"> </div>
        </div>
        <p class="fragment" style="font-size:80%">
        【答え】<br>
        平均\(1/2\),分散\(1/12\),標準偏差\(1/2\sqrt{3}\approx 0.29\)
        </p>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 期待値の線型性 </h4>
        <p>
        有限値を取る確率変数\(X,Y\),定数\(a,b\)について
        \[ E[aX+bY] = aE[X] + bE[Y] \]
        が成立する。
        </p>
        </div>
        <p style="font-size:70%"> これは総和・積分の性質より直ちに言えます。 </p>

        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 分散の計算公式 </h4>
        \[ V[X] = E[X^2] - (E[X])^2 \]
        </div>
        <p style="font-size:70%">
        【証明】<br>
        \(\mu = E[X]\)とおくと
        \[ \begin{aligned}
        V[X]&= E[(X-\mu)^2] = E[X^2-2\mu X+\mu^2]=E[X^2]-2\mu E[X]+\mu^2E[1] \\
            &= E[X^2]-2(E[X])^2+(E[X])^2\times 1 \\
            &= E[X^2] - (E[X])^2
        \end{aligned} \]
        <span style="float:right">□</span>
        </p>
        </section>

        <section>
        <h2 class="chapter-title"> 同時確率・周辺化 </h2>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 同時確率 </h4>
        <p>
        事象\(A_1,\cdots,A_n\)に対して
        \[ P(A_1\cap \cdots \cap A_n) \]
        を\(A_1,\cdots,A_n\)の<strong>同時確率</strong>と言い,
        \[ P(A_1,\cdots,A_n) \]
        と書く。
        </p>
        <p>
        同時確率\(P(X\in A,Y\in B)\)が
        \[ P(X\in A,Y\in B) = \int_B\int_A\rho(x,y)\mathrm{d}x\mathrm{d}y \]
        と表される時,\(\rho(x,y)\)を<strong>同時確率密度関数</strong>という。3変数以上でも同様である。
        </p>
        </div>
        </section>

        <section>
        <p>
        互いに素な集合\(B_1,B_2,\cdots,\)について
        \[ B_1\cup B_2\cup \cdots = \Omega\]
        と表されるならば,
        \[ (A\cap B_1)\cup (A\cap B_2) \cup \cdots = A \]
        が成立します。この左辺の各集合もやはり互いに素なので
        \[ P(A\cap B_1) + P(A\cap B_2) + \cdots = P(A) \]
        が成立します。
        </p>
        <div align="center"> <img width="500px" src="fig/marginalization.png"> </div>
        </section>

        <section>
        <p>
        ここでは同時確率\(P(A, B_i)\)を\(B_i\)について全て足し込んで,\(A\)の確率だけ求める(\(B\)を消去する)という事をしています。この作業を同時確率の<strong>周辺化</strong>と言います。特に,確率変数に関する周辺化が重要です。
        </p>
        <div class="block fragment" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 同時確率の周辺化 </h4>
        <p>
        確率変数\(X,Y\)に関する同時確率の,変数\(Y\)の値域全体での和を取る操作を<strong>周辺化</strong>という。
        </p>
        <p>
        すなわち,離散的な確率分布における周辺化は
        \[ P(X=x) = \sum_{i=1}^{\infty}P(X=x, Y=y_i) \]
        と行い,
        同時確率密度関数\(\rho\)で表される分布における周辺化は
        \[ P(X\in A) = \int_A\int_{-\infty}^{\infty}\rho(x, y)\mathrm{d}y\mathrm{d}x \]
        と行う。変数が増えても同様である。
        </p>
        </div>
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:80%">
        <h4 style="color:lightgreen"> 練習問題 </h4>
        <p>
        いびつなコイン\(A,B\)を投げた時の表・裏の出方が,以下の確率分布表に従っていたとします。
        \[ \begin{array}{|c|cc|} \hline
                      & \text{$A$:表} & \text{$A$:裏} \\ \hline
        \text{$B$:表} & 0.18 & 0.42 \\
        \text{$B$:裏} & 0.12 & 0.28 \\ \hline
        \end{array} \]
        これを周辺化してください。
        </p>
        </div>
        <p class="fragment" style="font-size:70%">
        \[ P(A:\text{表}) = P(A:\text{表}, B:\text{表}) + P(A:\text{表}, B:\text{裏}) = 0.18 + 0.12 = 0.3 \]
        従って\(P(A:\text{裏}) = 0.7\)
        \[ P(B:\text{表}) = P(A:\text{表}, B:\text{表}) + P(A:\text{裏}, B:\text{表}) = 0.18 + 0.42 = 0.6 \]
        従って\(P(B:\text{裏})=0.4\)
        </p>
        </section>

        <section>
        <p>
        確率変数\(X_1,X_2,\cdots,X_n\)を持つ分布に関する確率計算は
        </p>
        <ol>
          <li> 一旦,同時確率\( P(X_1,X_2,\cdots,X_n) \)を求める。 </li>
          <li> それを周辺化して知りたい事象の確率を求める。 </li>
        </ol>
        <p>
        という手順で行われる事がよくあります。
        </p>
        <p class="fragment">
        ここで,<strong>周辺化とは非常に計算量の多い作業である</strong>ということに注意しましょう。多くの変数についての総和・重積分を計算しなければならない為です。
        </p>
        <p class="fragment">
        そこで,後で説明する「事象の独立性」を使って周辺化する変数の数を減らしたり,モンテカルロ法などの高速な近似積分法を使う事が必要となります。
        </p>
        </section>

        <section>
        <h2 class="chapter-title"> 条件付き確率・独立性・ベイズの定理 </h2>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 条件付き確率 </h4>
        <p>
        \(P(A) > 0\)である時,
        \[ P(B\ |\ A) = \frac{P(A, B)}{P(A)} \]
        を<strong>\(A\)の下での\(B\)の条件付き確率</strong>と言う。
        </p>
        </div>
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        サイコロを振って奇数が出た時に,それが\(4\)以上である確率を計算しましょう。
        </p>
        </div>
        <p>
        \[ \begin{aligned}
        P(\text{$4$以上}\ |\ \text{奇数}) &= \frac{P(\text{$4$以上の奇数})}{P(\text{奇数})} \\
        &= \frac{\frac{1}{6}}{\frac{3}{6}} = \frac13 
        \end{aligned} \]
        </p>
        </section>

        <section>
        <blockquote style="font-size:90%">
        サイコロを振って奇数が出た時に,それが\(4\)以上である確率
        </blockquote>
        <p>
        とは一体何でしょうか？サイコロを振った時点でそれが\(4\)以上か否かは確定しているはずです。
        </p>
        <p class="fragment">
        この確率は主観的確率として解釈する事が可能です。つまり,何も知らない状態では
        \[ P(\text{$4$以上}) = \frac12 \]
        であったのが,「奇数が出た」という新たな情報を得ることによって
        \[ P(\text{$4$以上}\ |\ \text{奇数が出た}) = \frac13 \]
        に確信度が改訂されたのだと考える事が出来ます。
        </p>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 確率の常法定理 </h4>
        <p>
        \(P(A) > 0\)のとき
        \[ P(A,B) = P(A)P(B|A) \]
        が成立する。
        </p>
        <p>
        一般に
        \[ \begin{aligned}
        P(A_1,\cdots,A_n) = &P(A_1)P(A_2|A_1)P(A_3|A_1,A_2)\\
                            &\cdots P(A_n|A_1,\cdots,A_{n-1})
        \end{aligned} \]
        が成立する。
        </p>
        </div>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 独立性 </h4>
        <p>
        事象\(A,B\)に対して,
        \[ P(A\cap B) = P(A)P(B) \]
        が成立する時,これらの事象は<strong>独立</strong>であるという。そうでない時は<strong>従属</strong>であるという。
        </p>
        <p>
        </p>
        </div>
        <p>
        \(P(A) > 0\)であるならば\(A,B\)が独立であるということは
        \[ P(B) = P(B|A) \]
        を意味します。これは事象\(A\)が生じたという情報を得ても,事象\(B\)については何もわからないということだと解釈する事が出来ます。
        </p>
        </section>

        <section>
        <h2> ベイズの定理 </h2>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> ベイズの定理 </h4>
        <p>
        \(P(A),P(B)>0\)の時
        \[ P(B|A) = \frac{P(B)P(A|B)}{P(A)} \]
        が成立する。
        </p>
        </div>
        <p style="font-size:80%">
        【証明】<br>
        確率の常法定理より\(P(A),P(B)>0\)ならば
        \[ P(A,B) = P(A)P(B|A) = P(B)P(A|B) \]
        が成立するので両辺を\(P(A)\)で割る。
        <span style="float:right">□</span>
        </p>
        </section>

        <section>
        <p>
        ベイズの定理は純粋に数学的に導かれる定理ですが,主観的解釈と共に利用される事が多いです。
        </p>
        <p class="fragment">
        つまり,事象\(A\)が生じたという情報を得た事による,事象\(B\)が起きているという事の確信度\(P(B)\)の確信度\(P(B|A)\)への更新は
        \[ \color{yellow}{ P(B|A) = P(B)\times\frac{P(A|B)}{P(A)} } \]
        によって行われるべきだという事です。
        </p>
        <p class="fragment">
        この意味で\(P(B)\)を<strong>事前確率</strong>,\(P(B|A)\)を<strong>事後確率</strong>と言います。
        </p>
        </section>

        <section>
        <p>
        等式
        \[ \color{yellow}{ P(B|A) = P(B)\times\frac{P(A|B)}{P(A)} } \]
        の意味をもっとよく考えてみましょう。
        </p>
        <p>
        \(B\)であるという条件下で\(A\)が通常より起こり難いならば,
        \[ P(A|B) < P(A) \]
        となります。従って,この時は
        \[ P(B|A) < P(B) \]
        となります。これは「\(B\)という条件下では起こり難いはずの\(A\)が起こる」と「\(B\)であるという確信度が低下する」という事です。
        </p>
        <p>
        \(P(A|B) > P(A)\)の場合も同様の解釈を行う事が出来ます。
        </p>
        </section>

        <section>
        <p>
        確率の常法定理を使えば,同時確率の周辺化は
        \[ P(B)=\sum_{i=1}^{\infty}P(B,A_i) = \sum_{i=1}^{\infty}P(A_i)P(B|A_i) \]
        と書けます。これを使って,ベイズの定理を書き換えた形もよく利用されます。
        </p>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> ベイズの定理 </h4>
        <p>
        \(B_1,B_2,\cdots\)が互いに素で,\(\Omega=B_1\cup B_2\cup\cdots\)であるならば
        \[ P(B_i|A) = \frac{P(B_i)P(A|B_i)}{\displaystyle\sum_{i=1}^{\infty}P(B_i)P(A|B_i)} \]
        である。
        </p>
        </div>
        </section>

        <section style="font-size:90%">
        <div class="block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 練習問題 </h4>
        <p>
        ある検査を受けた時に
        </p>
        <ul>
          <li> ガンだと診断されるという事象を\(A\) </li>
          <li> 実際にガンであるという事象を\(B\) </li>
        </ul>
        <p>
        とします。
        \[ P(A|B) = 0.99,\quad P(A|B^c) = 0.005,\quad P(B)=0.001 \]
        であるとき,ガンだと診断された時に実際にガンである確率を求めて下さい。
        </p>
        </div>
        <p class="fragment" style="font-size:80%">
        【答え】<br>
        \[ \begin{aligned}
        P(B|A) &= \frac{P(B)P(A|B)}{P(B)P(A|B)+P(B^c)P(A|B^c)} \\
        &= \frac{0.001\times 0.99}{0.001\times 0.99 + 0.999\times 0.005} \\
        &\approx 16.5\%
        \end{aligned} \]
        </p>
        </section>

        <section>
        <h2 class="chapter-title"> 情報量・エントロピー </h2>
        </section>

        <section>
        <p>
        情報量とは一体なんでしょうか？直感的に考えて見ます。
        </p>
        <p class="fragment" data-fragment-index="1">
        分かり易い例として,文章の中の単語の情報量について考えましょう。
        </p>
        <blockquote class="fragment" data-fragment-index="1" style="font-size:90%">
          「そして」、「しかし」、「例えば」、「本節では」\(\cdots\)
        </blockquote>
        <p class="fragment" data-fragment-index="1">
        など,他の文章でも頻繁に登場する単語はその文章を理解する上でほとんど役に立ちません。
        </p>
        <p class="fragment" data-fragment-index="2">
        一方
        </p>
        <blockquote class="fragment" data-fragment-index="2" style="font-size:90%">
          「確率」、「事象」、「測度」、「分布」、\(\cdots\)
        </blockquote>
        <p class="fragment" data-fragment-index="2">
        などの単語が登場したら、それだけでその文書は確率論や統計学に関するものであろうと分かってしまいます。これらの単語は情報量が多い単語であると言えるでしょう。
        </p>
        </section>

        <section>
        <p>
        今の例から、<strong> 情報量は確率と深く関係している</strong>のではないかと考えられます。更に,<strong> 確率が小さい事象の持つ情報量は大きい</strong>であろうという事も分かります。
        </p>
        </section>

        <section style="font-size:80%">
        <p>
        そこで,事象\(A\)の情報量\(I(A)\)は,何らかの単調減少な関数\(f(x)\)によって
        \[ \color{yellow}{ I(A) = f(P(A)) } \]
        と表されると仮定してみましょう。
        </p>
        <p class="fragment">
        さらに,事象\(A,B\)が独立であるならば,\(A,B\)それぞれの持つ情報に重複は無いであろうと考えられるので,
        \[ \color{yellow}{ A,B\text{が独立ならば} I(A\cap B) = I(A) + I(B)} \]
        である事が期待されます。
        </p>
        <p class="fragment">
        この時\(P(A\cap B)=P(A)P(B)\)なので,
        \[ \color{yellow}{ f(P(A)P(B)) = f(P(A))+f(P(B)) } \]
        が成立しなければなりません。
        </p>
        <p class="fragment">
        このような性質を持つ,単調減少な\(f\)であれば良いので
        \[ \color{yellow}{ f(x) = -\log x } \]
        などが候補となります。以上の他,様々な考察に基いて情報量が定義されます。
        </p>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 情報量 </h4>
        <p>
        事象\(A\)の確率が\(P(A)\)である時
        \[ I(A) = -\log P(A) \]
        をこの事象の<strong>(選択)情報量</strong>という。
        </p>
        <p>
        \(\log\)の底は(何でも良いが),例えば\(2\)とすればよい。
        底が\(2\)の時の情報量の単位を<strong>ビット</strong>という。
        </p>
        </div>
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        歪みのないコインを3回振って,表が\(k\)回出たという事象を\(A_k\)とします。\(I(A_k)\)を計算しましょう。
        </p>
        </div>
        <p style="font-size:80%">
        【解答】<br>
        \[ P(A_k) = {}_nC_k\left(\frac{1}{2}\right)^3 \]
        なので
        \[ P(A_0) = \frac{1}{8},\ P(A_1)=\frac{3}{8},\ P(A_2)=\frac{3}{8},\ P(A_3)=\frac{1}{8} \]
        となるから,
        \[ I(A_0)=I(A_3)=-\log\frac{1}{8}=3,\ I(A_1)=I(A_2)=-\log\frac{3}{8} \approx 1.42 \]
        となる。
        </p>
        </section>

        <section style="font-size:80%">
        <p> 選択情報量の期待値が情報エントロピーです。 </p>
        <div class="block" style="border-color:pink;font-size:90%">
        <h4 style="color:pink"> 情報エントロピー </h4>
        <p>
        有限集合(サイズ\(n\))上の確率分布に対して,
        \[ \begin{aligned}
        H(X) &= \sum_{i=1}^{n}I(X=x_i)P(X=x_i)\\
        &= -\sum_{i=1}^{n}P(X=x_i)\log P(X=x_i)
        \end{aligned} \]
        を,確率分布の<strong>情報エントロピー</strong>や<strong>シャノン情報量</strong>と言う。<br>
        ただし\(P(X=x_i)=0\)の時は\(-P(X=x_i)\log P(X=x_i)=0\)とする。
        </p>
        </div>
        <p>
        連続的な確率分布に対しても,似た量
        \[ h(x) = -\int_{-\infty}^{\infty}\rho(x)\log \rho(x)\mathrm{d} x \]
        を考えてこれをエントロピーと呼びますが,これはシャノン情報量とは異なるので注意してください。
        (\(\rho(x)\)は確率「密度」なので\(-\log\rho(x)\)は選択情報量ではない。)
        </p>
        </section>

        <section>
        <div class="block" style="border-color:lightgreen;font-size:90%">
        <h4 style="color:lightgreen"> 例 </h4>
        <p>
        サイコロの出目の確率分布のエントロピーを計算してみましょう。出目に偏りがある場合はどうなるでしょうか？
        </p>
        </div>
        <p style="font-size:80%">
        出目に偏りが無い場合には,
        \[ H(X) = -\sum_{i=1}^{6}\frac{1}{6}\log\frac{1}{6}=-\log\frac{1}{6}\approx 2.585\]
        です。出目に偏りがある場合として,例えば1が出る確率を\(\frac{11}{60}\),6が出る確率を\(\frac{9}{60}\)としてみれば
        \[ \begin{aligned}
        H(X) &= -4\times \frac{1}{6}\log\frac{1}{6}-\frac{11}{60}\log\frac{11}{60}-\frac{9}{60}\log\frac{9}{60} \\
        &\approx 2.583 
        \end{aligned} \]
        少しエントロピーが小さくなりました。
        </p>
        </section>

        <section>
        <div class="block" style="border-color:pink;font-size:90%">
          <p>
          エントロピー
          \[ H(X) = -\sum_{i=1}^{n}P(X=x_i)\log P(X=x_i) \]
          は\(P(X=x_i)\)が全て等しい時に最大となる。
          </p>
        </div>
        </section>

        <section style="font-size:70%">
        <p>
        【証明】<br>
        ラグランジュの未定定数法を利用する。\(p_i = P(X=x_i)\)とおいて,
        \[ f(p_1,\cdots,p_n,\lambda) = -\sum_{i=1}^{n}p_i\log p_i + \lambda(p_1+\cdots +p_n - 1) \]
        とすると,
        \[ \frac{\partial f}{\partial p_i} = -\log p_i - 1 + \lambda,\quad \frac{\partial f}{\partial \lambda} = p_1+\cdots +p_n-1 \]
        であるので極値において
        \[ \lambda = \log p_i + 1,\quad p_1+\cdots + p_n = 1 \]
        が成り立つ。従って,\(H(X)\)が極値を取るとき
        \[ p_1 = \cdots = p_n = \frac{1}{n},\ \lambda = 1-\log n\]
        である。これが最大値である事は明らか。
        <span style="float:right">□</span>
        </p>
        </section>

        <section>
        <p>
        「エントロピー」という言葉を<strong>「乱雑さの度合い」</strong>と理解している人もいるでしょう。実際,統計力学におけるエントロピーと情報科学におけるエントロピーは定数倍を除いて一致します。
        </p>
        <p>
        直感的に言えば,今の定理より\(\Omega=\{x_1,\cdots,x_n\}\)上の確率分布のエントロピーが大きくなると,\(X=x_1,\cdots,x_n\)のいずれが出るかが全くのランダムに近づいていく(乱雑になっていく)という事になります。
        </p>
        <div align="center"> <img width="500px" src="fig/entropy1.png"> </div>
        </section>


        <section>
        <p>
        また,「情報量」と聞いて通常連想するのは<strong>「データの圧縮」</strong>ではないかと思います。
        <p>
        <p class="fragment" data-fragment-index="1">
        あるランダムなデータの列のエントロピーが小さい(シャノン情報量が少ない)という事は,そのデータ列が何らかのパターンを持っている(乱雑さが小さい)という事です。
そのパターンを利用してデータの圧縮を行う事が出来ます。
        </p>
        <ul class="fragment" data-fragment-index="1">
          <li> 出現頻度の高いデータ(選択情報量小)に短いbitを割り当てる </li>
          <li> 出現頻度の低いデータ(選択情報量大)に長いbitを割り当てる </li>
        </ul>
        </section>

        <section>
        <p>
        また,情報量は事象の独立性とも関係があります。統計学ではこの視点が特に重要であり、今後も登場すると思います。
        </p>
        <p>
        ２つの事象の間で情報のやり取りがあるならば,それらは確率的に独立ではないはずです。先ほど説明した独立性の定義
        \[ P(A,B)=P(A)P(B) \]
        では、「\(A,B\)が独立か否か」しかわかりませんが、情報量を測る事で<strong>「独立性の程度」</strong>を数値化出来ます。
        </p>
        <div align="center"> <img width="500px" src="fig/entropy2.png"> </div>
        </section>

        <section>
        <h2> 今回はここで終わります。 </h2>
        <p>
        次回は二項分布・正規分布・ポアソン分布他重要な確率分布,大数の法則,中心極限定理など重要な定理の紹介を行います。
        </p>
        </section>
      </div>
    </div>


    <script src="lib/reveal/lib/js/head.min.js"></script>
    <script src="lib/reveal/js/reveal.js"></script>

    <script>
      Reveal.initialize({
        width: 960,
        height: 640,
        controls: true,
        progress: false,
        history: true,
        overview: false,
        touch: true,
        center: false,
        rollingLinks: false,
        transition: "page",
        transitionSpeed: "default",

        // When scale != 1, positions of mouse events will be incorrect.
        minScale: 1.0,
        maxScale: 1.0,

        dependencies: [
					{ src: "lib/reveal/lib/js/classList.js", condition: function() { return !document.body.classList; } },
					{ src: "lib/reveal/plugin/highlight/highlight.js", async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: "lib/reveal/plugin/zoom-js/zoom.js", async: true, condition: function() { return !!document.body.classList; } },
					{ src: "lib/reveal/plugin/notes/notes.js", async: true, condition: function() { return !!document.body.classList; } }
          ]
      });

      // register event listeners
      require(["MathJax"], function (MathJax) {

        // Delay typesetting of slides
        function typeset (idx) {
          for (var i = idx - 2, n = idx + 2; i <= n; i++) {
            var slide = Reveal.getSlide(i);
            if (!slide) continue;
            if (!slide.typeset) {
              MathJax.Hub.Typeset(slide);
              slide.typeset = true;
            }
          }
        }

        function initializeGraphics (idx) {
          for (var i = idx - 2, n = idx + 2; i <= n; i++) {
            var slide = Reveal.getSlide(i);
            if (!slide) continue;
            var graphics = slide.getAttribute("graphics");
            if (graphics && !slide.initialized) {
              slide.initialized = true;
              (function () {
                var p = slide;
                require([graphics], function(g) {
                  if (g.initialize) g.initialize(p);
                });
              })();
            }
          }
        }

        function start (slide) {
          var graphics = slide.getAttribute("graphics");
          if (graphics) {
            require([graphics], function(g) { if (g.start) g.start(slide); });
          }
        }

        function stop (slide) {
          var graphics = slide.getAttribute("graphics");
          if (graphics) {
            require([graphics], function(g) { if (g.stop) g.stop(slide); });
          }
        }

        function simpleEvent (type) {
          var event = document.createEvent("HTMLEvents");
          event.initEvent(type, true, true);
          return event;
        }

        Reveal.addEventListener("slidechanged", function (event) {
          typeset(event.indexh);
          initializeGraphics(event.indexh);
          start(event.currentSlide);
          stop(event.previousSlide);
        });

        Reveal.addEventListener("fragmentshown", function (event) {
          var slide = Reveal.getCurrentSlide();
          var graphics = slide.getAttribute("graphics");
          if (graphics) {
            require([graphics], function(g) { if (g.proceed) g.proceed(slide); });
          }
        });

        console.log(Reveal.getIndices().h);
        typeset(Reveal.getIndices().h);
        initializeGraphics(Reveal.getIndices().h);
        start(Reveal.getCurrentSlide());
      });
    </script>
  </body>
</htl>
